---
layout: post
title: An example of XGBoost on Premier League Data
subtitle: Feature selection, data analysis, hyperparameter tuning and model evaluation
tags: [Machine Learning, Data Science, Python, Decision Trees, Football, Premier League]
comments: true
js:
    - https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML
---

In this post I will be using XGBoost to predict the outcome of a Premier League football club. Some constraints on the data
used include: trying to predict and classify the outcome of premier league games. The data is taken from 
[here](https://www.football-data.co.uk/).

The main features used include the betting odds from various bookmakers, the home and away team and the referee of the game.
Match statistics are not used and columns with match statistics are omitted from the training and testing data. Initial 
data cleaning performed on the data set includes one hot encoding to convert categorical data i.e. (Teams and Referees) 
into numerical data. The composition of teams making up the Premier League have also changed across the years, the spending
talent and management of many clubs have also changed across the years. These values are hard to capture and quantify, 
therefore I am hoping that using betting odds to predict the outcome of a game will be a good proxy for the quality of
a team. 

There will be different data and feature selection for the model to capture its performance. Since the feature and data
selection for each model is different, they cannot be compared directly. The purposes of this post is then to show the 
process of feature selection, data analysis, hyperparameter tuning and model evaluation. It is also to find the best 
selection of data and features to predict the outcome of the current season. 

Data Selection 1
--------------------------
__Features__:  
- Teams which have not been relegated for the past 9 seasons (Excluding the 23/24 season which will be used for
the final test) These teams include: {'Arsenal', 'Chelsea', 'Crystal Palace', 'Everton', 'Liverpool', 'Man City', 'Man United', 
'Tottenham', 'West Ham'}  
- Betting Data   
- Home & Away Data

Hyperparmeter Selection: Automatic (Using the Classic XGBoost Model for training) 

Using data for the past 9 seasons, we arrive observe the following confusion matrix.
![image]({{ '/assets/img/Data_Folder/2023-09-23-footy/result1.png' | relative_url }})

Results show that the model is better in predicting the outcome of a home win and away win. The model is not as good at
predicting the results of a draw. There could be several reasons behind this, betting data is heavily skewed towards one 
side winning and the odds of a draw are much lower than that of either side winning. In order to improve the model, we 
could further improve the hyperparameter choice through either GridSearchCV or RandomSearchCV.

Additionally, there is only a total of 728 rows of data. The amount of tabular data is insufficient given the number of 
classes the algorithm has to predict. With some insight, some clear limitations include 10 seasons being too long a time
and hence many clubs would have been subject to different financial and management evolutions. 

|          | Precision | Recall   | F1       |
|:---------|:----------|:---------|----------|
| Away Win | 0.450980  | 0.489362 | 0.469388 |
| Draw     | 0.188679  | 0.285714 | 0.227273 |
| Home Win | 0.697368  | 0.540816 | 0.609195 |

Using the 10th season of data (23/24) the following results are observed for the following matches.
![image]({{ '/assets/img/Data_Folder/2023-09-23-footy/result2.png' | relative_url }})

The predictions are relatively consistent with the previous results. 

